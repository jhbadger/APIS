#!/usr/bin/env ruby

require 'optparse'
require 'rubygems'
require 'dm-core'
require 'Newick'
require 'ostruct'
require 'fastercsv'
require 'ComboDB'
require 'ApisDB'

opts = OpenStruct.new

opts.all = false
opts.host = "mysql://access:access@mysql-lan-pro"
opts.storage = "misc_apis"
opts.proteindb = "phylodb"
opts.tree = false
opts.boot = false
opts.cut = false
opts.delim = false
opts.exp = false
opts.file = false
opts.schmidt = false
opts.relax = false
opts.limit = false

ARGV.options {|o|
  o.banner << " [dataset .. dataset..]"
  o.on("-a", "--all", "include all datasets in database (#{opts.all})") {|t| opts.all = true}
  o.on("-b", "--bootstrap", "include bootstrap value (#{opts.boot})") {|t| opts.boot = t}
  o.on("-c", "--cut", "separate file per dataset (#{opts.cut})") {|t| opts.cut = true}
  o.on("-d", "--delim-tab", "use tab delimiter (#{opts.delim})") {|t| opts.delim = true}
  o.on("-e ", "--expression ", String, "include datasets matching substring") {|t| opts.exp = t}
  o.on("-f ", "--file ", String, "only include ids from file") {|t| opts.file = t}
  o.on("-h ", "--host ", String, "database host (#{opts.host})") {|t| opts.host = t}
  o.on("-l ", "--limit ", Integer, "number of records to limit to") {|t| opts.limit = t}
  o.on("-p ", "--proteindb ", String, "protein database (default #{opts.proteindb})") {|t| opts.proteindb = t}
  o.on("-r", "--relax", "relaxed classification (#{opts.relax})") {|t| opts.relax = true}
  o.on("-s ", "--storage ", String, "storage database (default #{opts.storage})") {|t| opts.storage = t}
  o.on("-t", "--tree", "include tree in file (#{opts.tree})") {|t| opts.tree = t}
   o.on("-z", "--filtered", "only include schmidt filtered (#{opts.schmidt})") {|t| opts.schmidt = t}
  begin
    o.parse!
  rescue
    STDERR << $!.message << "\n"
    STDERR << o 
    exit(1)
  end
  if (ARGV.size < 1 && (!opts.all && !opts.exp))
    STDERR << o
    exit(1)
  end
}

DataMapper.setup(:default, opts.host + "/" + opts.storage)
DataMapper.setup(:combodb, opts.host + "/" + opts.proteindb)

if (opts.all || opts.exp)
  repository(:default).adapter.select("select dataset from dataset").each do |dataset|
    ARGV.push(dataset) if (opts.exp.nil? || dataset =~/#{opts.exp}/)
  end
end

if (opts.delim)
  opts.delim = "\t"
else
  opts.delim = ","
end

out = Hash.new

header = ["Seq Name", "Dataset", "Length", "Annotation", "Standard Classification", "Standard Tax Id"]
header.push("Relaxed Classification", "Relaxed Tax Id") if opts.relax
header.push("Bootstrap") if (opts.boot)
header.push("Tree") if (opts.tree)

if (opts.tree || opts.relax)
  STDERR << "Loading Taxonomy...\n"
  taxdb = repository(:combodb){Contig.tax}
else
  taxdb = nil
end

def summarizeClass(tax)
  t = ""
  tid = nil
  goodRank = ""
  tax.each do |rank|
    if (rank !="Undefined" && !rank.nil?)
      t += "; " if t != ""
      t += rank
      break if rank == "Mixed"
    end
    goodRank = rank
  end
  t = "NO_TREE" if t == ""
  if (goodRank != "")
    tid = repository(:combodb).adapter.select("select ncbi_taxon_id from phylodb_annotation.taxon, phylodb_annotation.taxon_name " + 
      "where name = '#{goodRank}' and phylodb_annotation.taxon.taxon_id = phylodb_annotation.taxon_name .taxon_id limit 1")
  end
  return t, tid
end


exist = Dir.glob("*.csv") + Dir.glob("*.tab")
exist = exist.collect{|x| x.gsub(".csv","").gsub(".tab","")}
ARGV = ARGV - exist


query = "SELECT count(*) FROM sequence WHERE dataset in ('#{ARGV.join('\',\'')}')"
STDERR << "Counting sequences...\n"
num = repository(:default).adapter.select(query).first
milestone = num / 200.0
printID = Hash.new

if (opts.file)
  STDERR << "Loading file of ids...\n"
  File.new(opts.file).each do |line|
    id, rest = line.chomp.split(" ")
    printID[id] = true
  end
end

file = STDOUT
file << header.to_csv({:col_sep=>opts.delim}) if (!opts.cut)
ext = ".csv"
ext = ".tab" if (opts.delim)
count = 0
STDERR << "Writing Spreadsheet...\n"
ARGV.each do |dataset|
  if (opts.cut)
    file.close if file != STDOUT
    file = File.new(dataset + ext, "w")
    file << header.to_csv({:col_sep=>opts.delim})
  end
  query =  "SELECT sequence.seq_name, sequence.dataset, length(sequence), annotation, "
  query += "kingdom, phylum, class, ord, family, genus, species, tree"
  query += " FROM sequence "
  query += "LEFT JOIN classification ON classification.seq_name = sequence.seq_name "
  query += "AND sequence.dataset = classification.dataset " 
  query += "LEFT JOIN tree ON tree.seq_name = sequence.seq_name "
  query += "AND sequence.dataset = tree.dataset " 
  query += "LEFT JOIN annotation ON annotation.seq_name = sequence.seq_name "
  query += "AND sequence.dataset = annotation.dataset and annotation.source='APIS' "
  query += " LEFT JOIN schmidt_filtered ON schmidt_filtered.seq_name = sequence.seq_name " if (opts.schmidt)
  query += "WHERE sequence.dataset='#{dataset}'"
  query += " AND filtered = 1 " if (opts.schmidt)
  query += " LIMIT #{opts.limit}" if (opts.limit)
  repository(:default).adapter.select(query).each do |row|
    next if (opts.file && !printID[row[0]])
    list = row.to_a
    tree = list.pop
    begin
      newick = NewickTree.new(tree) if (!tree.nil? && (opts.boot || opts.relax))
    rescue
      newick = nil
    end
    tax, tid = summarizeClass(list[4..10])
    if (opts.relax)
      if (tree.nil? || newick.nil?)
        rtax = ""
        rtid = nil
      else
        relax = newick.createClassification(list[0], taxdb, nil, true)
        rtax, rtid = summarizeClass(relax)
      end
      list[4..10] = [tax, tid, rtax, rtid]
    else
      list[4..10] = [tax, tid]
    end
    if (opts.boot)
      if (tree.nil? || newick.nil?)
        list.push(nil)
      else
        list.push(newick.findNode(row[0]).parent.name)
      end
    end
    list.push(tree) if (opts.tree)
    file << list.to_csv({:col_sep=>opts.delim})
    count += 1
    STDERR << ((count*1000)/num)/10.0 << "% completed...\n" if (count % milestone == 0)
    row = nil
    list = nil
  end
end
file.close if file != STDOUT